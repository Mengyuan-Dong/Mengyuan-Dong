{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this skeleton, you need to install torchtext, and optionally spacy. \n",
    "# It also uses pretrained word embeddings from glove.6B.100d which is around 850 MB. You can skip using it if you don't have enough \n",
    "# memory to work with. But training will be faster if you use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /Users/dmy/opt/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /Users/dmy/opt/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from en_core_web_sm==2.3.1) (2.3.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/dmy/opt/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: thinc==7.4.1 in /Users/dmy/opt/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/dmy/opt/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/dmy/opt/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.9.6)\n",
      "Requirement already satisfied: setuptools in /Users/dmy/opt/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (50.3.1.post20201107)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/dmy/opt/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.24.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/dmy/opt/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.51.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/dmy/opt/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.4)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/dmy/opt/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/dmy/opt/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/dmy/opt/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/dmy/opt/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/dmy/opt/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/dmy/opt/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/dmy/opt/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/dmy/opt/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dmy/opt/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.11.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/dmy/opt/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/dmy/opt/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.4.0)\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "#### Section 1: Spacy (optional) ###\n",
    "# Uncomment this lines if you are using spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "prefix_re = spacy.util.compile_prefix_regex(nlp.Defaults.prefixes)\n",
    "suffix_re = spacy.util.compile_suffix_regex(nlp.Defaults.suffixes)\n",
    "infix_re = re.compile(r'''[-~]''')\n",
    "!python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Section 2: Tokenizer ###\n",
    "# create a tokenizer function\n",
    "def tokenizer(text): \n",
    "    # return a list of words. You may skip the stop words defined by spacy or nltk lib\n",
    "    doc = nlp(text)\n",
    "    result = []\n",
    "    for token in doc:\n",
    "        ent = nlp.vocab[token.text]\n",
    "        if ent.is_stop == False:\n",
    "            result.append(token.text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    my_doc = nlp(text)\n",
    "    token_list = []\n",
    "    for token in my_doc:\n",
    "        token_list.append(token.text)\n",
    "    filtered_sentence = []\n",
    "    for word in token_list:\n",
    "        lexeme = nlp.vocab[word]\n",
    "        if lexeme.is_stop == False:\n",
    "            filtered_sentence.append(word)\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize = tokenizer, lower=True, include_lengths = True)\n",
    "LABEL = data.LabelField(dtype = torch.long)\n",
    "fields = {'reviewText': ('t', TEXT), 'sentiment': ('l', LABEL)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Section 3: Datasets ###\n",
    "# while you experiment, use the small datasets. Final training and evaluation needs to be done with large datasets. \n",
    "#suffix = 'small-'\n",
    "suffix = 'large-'\n",
    "dataFolder = '/Users/dmy/Downloads' # keep all your data files in a single folder\n",
    "\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "                                        path = dataFolder, \n",
    "                                        train = suffix + 'clean-train.json', # json file\n",
    "                                        validation = suffix + 'clean-val.json',# json file\n",
    "                                        test = suffix + 'clean-val.json',# json file\n",
    "                                        format = 'json', # json file\n",
    "                                        fields = fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 53760\n",
      "Number of testing examples: 30240\n",
      "{'t': ['koi', 'scrub', 'pants', 'fit', 'better', '.'], 'l': 'bad'}\n"
     ]
    }
   ],
   "source": [
    "#### Section 4: Vocabulary ###\n",
    "\n",
    "# You can use GloVe vocabulary to train your model faster towards convergence or build up your own embeddings. \n",
    "# If you are not using the GloVe embeddings, you will need to comment out the embedding weight transfer to model in \n",
    "# Section 9\n",
    "\n",
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "#Local vocabulary\n",
    "# TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "# LABEL.build_vocab(train_data)\n",
    "\n",
    "#GloVe vocabulary\n",
    "TEXT.build_vocab(train_data, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "# Check if it worked\n",
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')\n",
    "print(vars(train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Section 5: Iterators ###\n",
    "# Iterators organizes datasets into batches and feeds them into the model. In this skeletion, we use packed padded sequence\n",
    "# to make sure that all the input data points are of the same size and they do not incur unnecessary computation. Read more \n",
    "# about packed padded sequence here: https://stackoverflow.com/questions/51030782/why-do-we-pack-the-sequences-in-pytorch\n",
    "# For that, we need to sort the samples in each batch in decreasing order of number of words.\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    sort = False, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    sort_key = lambda x: len(x.t),\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Section 6: Vanilla RNN ###\n",
    "\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        # Add your network's trainable layers here.\n",
    "        self.rnn = nn.RNN(embedding_dim, \n",
    "                          hidden_dim, \n",
    "                          num_layers=n_layers, \n",
    "                          bidirectional=bidirectional, \n",
    "                          dropout=dropout)\n",
    "    \n",
    "        self.fc1 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    " #        embedded = self.dropout(self.embedding(text))\n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        #pack sequence. Clambing the lengths to avoid errors in some bugs\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.clamp(min=1, max=50))\n",
    "        \n",
    "        # now packed_embedded is the input to your model. You can do whatever you want to do from this point\n",
    "        packed_output, hidden = self.rnn(packed_embedded)\n",
    "        output = self.fc1(hidden[-1,:,:])\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Section 7: Advanced Model ###\n",
    "\n",
    "class AdvancedModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        # Add your network's trainable layers here.\n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "       # embedded = self.dropout(self.embedding(text))\n",
    "        embedded = self.embedding(text)\n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        #pack sequence. Clambing the lengths to avoid errors in some bugs\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.clamp(min=1, max=50))\n",
    "        \n",
    "        # now packed_embedded is the input to your model. You can do whatever you want to do from this point\n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        output = self.fc1(hidden)\n",
    "        output = self.dropout(self.fc2(output))\n",
    "                \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Section 8: Create your models ###\n",
    "### A.Vanilla RNN\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 3\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = VanillaRNN(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT, \n",
    "            PAD_IDX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Section 8: Create your models ###\n",
    "### LSTM RNN\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 3\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "modelL = AdvancedModel(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT, \n",
    "            PAD_IDX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19272, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5856,  0.1937,  2.7073,  ..., -0.0805,  2.0212, -0.2180],\n",
       "        [ 0.9062, -0.6399, -2.0356,  ...,  0.2262,  0.2828, -1.4489],\n",
       "        [-0.3398,  0.2094,  0.4635,  ..., -0.2339,  0.4730, -0.0288],\n",
       "        ...,\n",
       "        [-0.3582, -1.1579, -0.1634,  ...,  0.5312, -0.8237, -0.3024],\n",
       "        [-0.1346,  1.4445,  0.0270,  ...,  0.1019, -0.3709, -0.7011],\n",
       "        [-0.5231,  1.1769, -0.6864,  ..., -0.2238, -1.0347,  0.8426]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Section 9: Transfer pretrained weights for word embeddings from GloVe ###\n",
    "# Must be commented out if you are not using GloVe embeddings\n",
    "\n",
    "### Vanilla RNN\n",
    "\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19272, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5856,  0.1937,  2.7073,  ..., -0.0805,  2.0212, -0.2180],\n",
       "        [ 0.9062, -0.6399, -2.0356,  ...,  0.2262,  0.2828, -1.4489],\n",
       "        [-0.3398,  0.2094,  0.4635,  ..., -0.2339,  0.4730, -0.0288],\n",
       "        ...,\n",
       "        [-0.3582, -1.1579, -0.1634,  ...,  0.5312, -0.8237, -0.3024],\n",
       "        [-0.1346,  1.4445,  0.0270,  ...,  0.1019, -0.3709, -0.7011],\n",
       "        [-0.5231,  1.1769, -0.6864,  ..., -0.2238, -1.0347,  0.8426]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### B. LSTM RNN\n",
    "\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)\n",
    "modelL.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Section 10: Optimizer and Loss \n",
    "# Feel free to use any you want\n",
    "### Vanilla RNN\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "#criterion = nn.NLLLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSTM RNN\n",
    "optimizer = optim.Adam(modelL.parameters())\n",
    "\n",
    "#criterion = nn.NLLLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "modelL = modelL.to(device)\n",
    "criterion = criterion.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    predictedLabel = torch.argmax(torch.exp(preds), dim=1)\n",
    "    correct = (predictedLabel == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Section 11: Training process\n",
    "# Feel free to change\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text, text_lengths = batch.t\n",
    "        \n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.l)\n",
    "        \n",
    "        acc = accuracy(predictions, batch.l)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Section 11: Evaluation process\n",
    "# Feel free to change\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text, text_lengths = batch.t\n",
    "            \n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.l)\n",
    "            \n",
    "            acc = accuracy(predictions, batch.l)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 2m 10s\n",
      "\tTrain Loss: 0.707 | Train Acc: 70.46%\n",
      "\t Val. Loss: 0.662 |  Val. Acc: 72.47%\n",
      "Epoch: 02 | Epoch Time: 2m 9s\n",
      "\tTrain Loss: 0.611 | Train Acc: 74.57%\n",
      "\t Val. Loss: 0.617 |  Val. Acc: 74.17%\n",
      "Epoch: 03 | Epoch Time: 2m 8s\n",
      "\tTrain Loss: 0.549 | Train Acc: 77.62%\n",
      "\t Val. Loss: 0.617 |  Val. Acc: 75.03%\n",
      "Epoch: 04 | Epoch Time: 2m 9s\n",
      "\tTrain Loss: 0.516 | Train Acc: 79.35%\n",
      "\t Val. Loss: 0.603 |  Val. Acc: 75.61%\n",
      "Epoch: 05 | Epoch Time: 2m 17s\n",
      "\tTrain Loss: 0.492 | Train Acc: 80.28%\n",
      "\t Val. Loss: 0.613 |  Val. Acc: 75.72%\n",
      "Epoch: 06 | Epoch Time: 2m 20s\n",
      "\tTrain Loss: 0.467 | Train Acc: 81.58%\n",
      "\t Val. Loss: 0.621 |  Val. Acc: 76.25%\n",
      "Epoch: 07 | Epoch Time: 2m 23s\n",
      "\tTrain Loss: 0.449 | Train Acc: 82.52%\n",
      "\t Val. Loss: 0.619 |  Val. Acc: 75.93%\n",
      "Epoch: 08 | Epoch Time: 2m 25s\n",
      "\tTrain Loss: 0.437 | Train Acc: 82.90%\n",
      "\t Val. Loss: 0.610 |  Val. Acc: 76.06%\n",
      "Epoch: 09 | Epoch Time: 2m 25s\n",
      "\tTrain Loss: 0.422 | Train Acc: 83.72%\n",
      "\t Val. Loss: 0.611 |  Val. Acc: 76.57%\n",
      "Epoch: 10 | Epoch Time: 2m 22s\n",
      "\tTrain Loss: 0.406 | Train Acc: 84.35%\n",
      "\t Val. Loss: 0.624 |  Val. Acc: 75.99%\n",
      "Epoch: 11 | Epoch Time: 2m 22s\n",
      "\tTrain Loss: 0.402 | Train Acc: 84.53%\n",
      "\t Val. Loss: 0.648 |  Val. Acc: 76.04%\n",
      "Epoch: 12 | Epoch Time: 2m 24s\n",
      "\tTrain Loss: 0.384 | Train Acc: 85.40%\n",
      "\t Val. Loss: 0.657 |  Val. Acc: 76.31%\n",
      "Epoch: 13 | Epoch Time: 2m 26s\n",
      "\tTrain Loss: 0.382 | Train Acc: 85.43%\n",
      "\t Val. Loss: 0.652 |  Val. Acc: 75.43%\n",
      "Epoch: 14 | Epoch Time: 2m 26s\n",
      "\tTrain Loss: 0.372 | Train Acc: 85.99%\n",
      "\t Val. Loss: 0.678 |  Val. Acc: 75.69%\n",
      "Epoch: 15 | Epoch Time: 2m 29s\n",
      "\tTrain Loss: 0.367 | Train Acc: 86.21%\n",
      "\t Val. Loss: 0.640 |  Val. Acc: 76.13%\n",
      "Epoch: 16 | Epoch Time: 2m 30s\n",
      "\tTrain Loss: 0.362 | Train Acc: 86.41%\n",
      "\t Val. Loss: 0.630 |  Val. Acc: 75.51%\n",
      "Epoch: 17 | Epoch Time: 2m 29s\n",
      "\tTrain Loss: 0.351 | Train Acc: 86.89%\n",
      "\t Val. Loss: 0.684 |  Val. Acc: 75.76%\n",
      "Epoch: 18 | Epoch Time: 2m 26s\n",
      "\tTrain Loss: 0.347 | Train Acc: 87.07%\n",
      "\t Val. Loss: 0.689 |  Val. Acc: 75.82%\n",
      "Epoch: 19 | Epoch Time: 2m 27s\n",
      "\tTrain Loss: 0.348 | Train Acc: 87.01%\n",
      "\t Val. Loss: 0.673 |  Val. Acc: 75.71%\n",
      "Epoch: 20 | Epoch Time: 2m 27s\n",
      "\tTrain Loss: 0.340 | Train Acc: 87.30%\n",
      "\t Val. Loss: 0.714 |  Val. Acc: 74.48%\n",
      "Epoch: 21 | Epoch Time: 2m 26s\n",
      "\tTrain Loss: 0.342 | Train Acc: 87.23%\n",
      "\t Val. Loss: 0.686 |  Val. Acc: 75.65%\n",
      "Epoch: 22 | Epoch Time: 2m 21s\n",
      "\tTrain Loss: 0.340 | Train Acc: 87.44%\n",
      "\t Val. Loss: 0.698 |  Val. Acc: 74.96%\n",
      "Epoch: 23 | Epoch Time: 2m 8s\n",
      "\tTrain Loss: 0.338 | Train Acc: 87.57%\n",
      "\t Val. Loss: 0.682 |  Val. Acc: 75.09%\n",
      "Epoch: 24 | Epoch Time: 2m 7s\n",
      "\tTrain Loss: 0.333 | Train Acc: 87.69%\n",
      "\t Val. Loss: 0.680 |  Val. Acc: 75.52%\n",
      "Epoch: 25 | Epoch Time: 2m 8s\n",
      "\tTrain Loss: 0.328 | Train Acc: 88.05%\n",
      "\t Val. Loss: 0.690 |  Val. Acc: 74.91%\n",
      "Epoch: 26 | Epoch Time: 2m 7s\n",
      "\tTrain Loss: 0.325 | Train Acc: 88.15%\n",
      "\t Val. Loss: 0.696 |  Val. Acc: 75.48%\n",
      "Epoch: 27 | Epoch Time: 2m 7s\n",
      "\tTrain Loss: 0.320 | Train Acc: 88.29%\n",
      "\t Val. Loss: 0.707 |  Val. Acc: 75.83%\n",
      "Epoch: 28 | Epoch Time: 2m 9s\n",
      "\tTrain Loss: 0.317 | Train Acc: 88.38%\n",
      "\t Val. Loss: 0.694 |  Val. Acc: 75.60%\n",
      "Epoch: 29 | Epoch Time: 2m 7s\n",
      "\tTrain Loss: 0.316 | Train Acc: 88.34%\n",
      "\t Val. Loss: 0.755 |  Val. Acc: 75.02%\n",
      "Epoch: 30 | Epoch Time: 2m 8s\n",
      "\tTrain Loss: 0.319 | Train Acc: 88.23%\n",
      "\t Val. Loss: 0.730 |  Val. Acc: 75.35%\n",
      "Epoch: 31 | Epoch Time: 2m 8s\n",
      "\tTrain Loss: 0.309 | Train Acc: 88.90%\n",
      "\t Val. Loss: 0.738 |  Val. Acc: 75.70%\n",
      "Epoch: 32 | Epoch Time: 2m 8s\n",
      "\tTrain Loss: 0.309 | Train Acc: 88.66%\n",
      "\t Val. Loss: 0.729 |  Val. Acc: 75.00%\n",
      "Epoch: 33 | Epoch Time: 2m 8s\n",
      "\tTrain Loss: 0.305 | Train Acc: 88.91%\n",
      "\t Val. Loss: 0.728 |  Val. Acc: 75.43%\n",
      "Epoch: 34 | Epoch Time: 2m 9s\n",
      "\tTrain Loss: 0.303 | Train Acc: 88.97%\n",
      "\t Val. Loss: 0.710 |  Val. Acc: 75.23%\n",
      "Epoch: 35 | Epoch Time: 2m 12s\n",
      "\tTrain Loss: 0.301 | Train Acc: 89.08%\n",
      "\t Val. Loss: 0.737 |  Val. Acc: 75.36%\n",
      "Epoch: 36 | Epoch Time: 2m 9s\n",
      "\tTrain Loss: 0.301 | Train Acc: 89.05%\n",
      "\t Val. Loss: 0.749 |  Val. Acc: 75.55%\n",
      "Epoch: 37 | Epoch Time: 2m 19s\n",
      "\tTrain Loss: 0.302 | Train Acc: 89.02%\n",
      "\t Val. Loss: 0.727 |  Val. Acc: 74.66%\n",
      "Epoch: 38 | Epoch Time: 2m 11s\n",
      "\tTrain Loss: 0.299 | Train Acc: 89.22%\n",
      "\t Val. Loss: 0.751 |  Val. Acc: 75.51%\n",
      "Epoch: 39 | Epoch Time: 2m 13s\n",
      "\tTrain Loss: 0.297 | Train Acc: 89.34%\n",
      "\t Val. Loss: 0.748 |  Val. Acc: 75.30%\n",
      "Epoch: 40 | Epoch Time: 2m 14s\n",
      "\tTrain Loss: 0.299 | Train Acc: 89.15%\n",
      "\t Val. Loss: 0.769 |  Val. Acc: 74.79%\n",
      "Epoch: 41 | Epoch Time: 2m 14s\n",
      "\tTrain Loss: 0.297 | Train Acc: 89.21%\n",
      "\t Val. Loss: 0.740 |  Val. Acc: 75.40%\n",
      "Epoch: 42 | Epoch Time: 2m 19s\n",
      "\tTrain Loss: 0.296 | Train Acc: 89.18%\n",
      "\t Val. Loss: 0.754 |  Val. Acc: 75.44%\n",
      "Epoch: 43 | Epoch Time: 2m 19s\n",
      "\tTrain Loss: 0.296 | Train Acc: 89.26%\n",
      "\t Val. Loss: 0.799 |  Val. Acc: 74.33%\n",
      "Epoch: 44 | Epoch Time: 2m 18s\n",
      "\tTrain Loss: 0.294 | Train Acc: 89.36%\n",
      "\t Val. Loss: 0.754 |  Val. Acc: 74.45%\n",
      "Epoch: 45 | Epoch Time: 2m 21s\n",
      "\tTrain Loss: 0.295 | Train Acc: 89.30%\n",
      "\t Val. Loss: 0.777 |  Val. Acc: 75.41%\n",
      "Epoch: 46 | Epoch Time: 2m 22s\n",
      "\tTrain Loss: 0.295 | Train Acc: 89.38%\n",
      "\t Val. Loss: 0.740 |  Val. Acc: 75.21%\n",
      "Epoch: 47 | Epoch Time: 2m 23s\n",
      "\tTrain Loss: 0.289 | Train Acc: 89.60%\n",
      "\t Val. Loss: 0.807 |  Val. Acc: 75.01%\n",
      "Epoch: 48 | Epoch Time: 2m 24s\n",
      "\tTrain Loss: 0.284 | Train Acc: 89.78%\n",
      "\t Val. Loss: 0.781 |  Val. Acc: 75.21%\n",
      "Epoch: 49 | Epoch Time: 2m 21s\n",
      "\tTrain Loss: 0.288 | Train Acc: 89.59%\n",
      "\t Val. Loss: 0.759 |  Val. Acc: 74.54%\n",
      "Epoch: 50 | Epoch Time: 2m 20s\n",
      "\tTrain Loss: 0.288 | Train Acc: 89.66%\n",
      "\t Val. Loss: 0.765 |  Val. Acc: 74.89%\n"
     ]
    }
   ],
   "source": [
    "#### Section 12: Train\n",
    "\n",
    "# You need to change this name for each model.\n",
    "t1 = time.time()\n",
    "loss1=[]\n",
    "acc1=[]\n",
    "val_acc1=[]\n",
    "modelOutputName = 'vanilla-rnn.pt'\n",
    "\n",
    "N_EPOCHS = 50\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), modelOutputName)\n",
    "    loss1.append(train_loss)\n",
    "    acc1.append(train_acc)\n",
    "    val_acc1.append(valid_acc)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 7m 14s\n",
      "\tTrain Loss: 0.630 | Train Acc: 73.47%\n",
      "\t Val. Loss: 0.553 |  Val. Acc: 77.19%\n",
      "Epoch: 02 | Epoch Time: 8m 10s\n",
      "\tTrain Loss: 0.506 | Train Acc: 79.35%\n",
      "\t Val. Loss: 0.533 |  Val. Acc: 77.77%\n",
      "Epoch: 03 | Epoch Time: 8m 52s\n",
      "\tTrain Loss: 0.424 | Train Acc: 83.13%\n",
      "\t Val. Loss: 0.565 |  Val. Acc: 77.96%\n",
      "Epoch: 04 | Epoch Time: 9m 15s\n",
      "\tTrain Loss: 0.341 | Train Acc: 86.69%\n",
      "\t Val. Loss: 0.575 |  Val. Acc: 77.38%\n",
      "Epoch: 05 | Epoch Time: 8m 39s\n",
      "\tTrain Loss: 0.256 | Train Acc: 90.41%\n",
      "\t Val. Loss: 0.730 |  Val. Acc: 77.01%\n",
      "Epoch: 06 | Epoch Time: 7m 13s\n",
      "\tTrain Loss: 0.180 | Train Acc: 93.31%\n",
      "\t Val. Loss: 0.808 |  Val. Acc: 77.41%\n",
      "Epoch: 07 | Epoch Time: 7m 18s\n",
      "\tTrain Loss: 0.120 | Train Acc: 95.59%\n",
      "\t Val. Loss: 1.145 |  Val. Acc: 76.76%\n",
      "Epoch: 08 | Epoch Time: 7m 23s\n",
      "\tTrain Loss: 0.080 | Train Acc: 97.04%\n",
      "\t Val. Loss: 1.293 |  Val. Acc: 77.00%\n",
      "Epoch: 09 | Epoch Time: 10m 23s\n",
      "\tTrain Loss: 0.057 | Train Acc: 98.00%\n",
      "\t Val. Loss: 1.603 |  Val. Acc: 76.16%\n",
      "Epoch: 10 | Epoch Time: 9m 53s\n",
      "\tTrain Loss: 0.046 | Train Acc: 98.34%\n",
      "\t Val. Loss: 1.599 |  Val. Acc: 75.79%\n",
      "Epoch: 11 | Epoch Time: 10m 26s\n",
      "\tTrain Loss: 0.037 | Train Acc: 98.69%\n",
      "\t Val. Loss: 1.812 |  Val. Acc: 76.84%\n",
      "Epoch: 12 | Epoch Time: 10m 1s\n",
      "\tTrain Loss: 0.030 | Train Acc: 98.95%\n",
      "\t Val. Loss: 1.805 |  Val. Acc: 77.23%\n",
      "Epoch: 13 | Epoch Time: 9m 53s\n",
      "\tTrain Loss: 0.028 | Train Acc: 99.07%\n",
      "\t Val. Loss: 1.951 |  Val. Acc: 76.77%\n",
      "Epoch: 14 | Epoch Time: 13m 20s\n",
      "\tTrain Loss: 0.024 | Train Acc: 99.20%\n",
      "\t Val. Loss: 1.981 |  Val. Acc: 76.42%\n",
      "Epoch: 15 | Epoch Time: 8m 18s\n",
      "\tTrain Loss: 0.023 | Train Acc: 99.22%\n",
      "\t Val. Loss: 2.114 |  Val. Acc: 76.87%\n",
      "Epoch: 16 | Epoch Time: 8m 22s\n",
      "\tTrain Loss: 0.019 | Train Acc: 99.31%\n",
      "\t Val. Loss: 2.235 |  Val. Acc: 76.57%\n",
      "Epoch: 17 | Epoch Time: 8m 42s\n",
      "\tTrain Loss: 0.020 | Train Acc: 99.28%\n",
      "\t Val. Loss: 2.066 |  Val. Acc: 76.29%\n",
      "Epoch: 18 | Epoch Time: 8m 57s\n",
      "\tTrain Loss: 0.020 | Train Acc: 99.32%\n",
      "\t Val. Loss: 1.901 |  Val. Acc: 76.92%\n",
      "Epoch: 19 | Epoch Time: 8m 54s\n",
      "\tTrain Loss: 0.017 | Train Acc: 99.42%\n",
      "\t Val. Loss: 2.028 |  Val. Acc: 76.35%\n",
      "Epoch: 20 | Epoch Time: 8m 55s\n",
      "\tTrain Loss: 0.016 | Train Acc: 99.44%\n",
      "\t Val. Loss: 2.179 |  Val. Acc: 76.76%\n",
      "Epoch: 21 | Epoch Time: 8m 58s\n",
      "\tTrain Loss: 0.017 | Train Acc: 99.41%\n",
      "\t Val. Loss: 1.950 |  Val. Acc: 76.67%\n",
      "Epoch: 22 | Epoch Time: 9m 30s\n",
      "\tTrain Loss: 0.014 | Train Acc: 99.51%\n",
      "\t Val. Loss: 2.210 |  Val. Acc: 75.97%\n",
      "Epoch: 23 | Epoch Time: 9m 5s\n",
      "\tTrain Loss: 0.016 | Train Acc: 99.43%\n",
      "\t Val. Loss: 2.067 |  Val. Acc: 76.69%\n",
      "Epoch: 24 | Epoch Time: 8m 50s\n",
      "\tTrain Loss: 0.014 | Train Acc: 99.48%\n",
      "\t Val. Loss: 2.285 |  Val. Acc: 77.13%\n",
      "Epoch: 25 | Epoch Time: 9m 4s\n",
      "\tTrain Loss: 0.011 | Train Acc: 99.59%\n",
      "\t Val. Loss: 2.405 |  Val. Acc: 76.92%\n",
      "Epoch: 26 | Epoch Time: 8m 50s\n",
      "\tTrain Loss: 0.015 | Train Acc: 99.49%\n",
      "\t Val. Loss: 2.003 |  Val. Acc: 75.99%\n",
      "Epoch: 27 | Epoch Time: 8m 25s\n",
      "\tTrain Loss: 0.012 | Train Acc: 99.54%\n",
      "\t Val. Loss: 2.214 |  Val. Acc: 76.97%\n",
      "Epoch: 28 | Epoch Time: 8m 15s\n",
      "\tTrain Loss: 0.013 | Train Acc: 99.56%\n",
      "\t Val. Loss: 2.219 |  Val. Acc: 76.36%\n",
      "Epoch: 29 | Epoch Time: 8m 16s\n",
      "\tTrain Loss: 0.009 | Train Acc: 99.70%\n",
      "\t Val. Loss: 2.360 |  Val. Acc: 76.93%\n",
      "Epoch: 30 | Epoch Time: 8m 16s\n",
      "\tTrain Loss: 0.011 | Train Acc: 99.60%\n",
      "\t Val. Loss: 2.168 |  Val. Acc: 76.91%\n"
     ]
    }
   ],
   "source": [
    "#### Section 12: Train\n",
    "\n",
    "# You need to change this name for each model.\n",
    "t2 = time.time()\n",
    "loss2=[]\n",
    "acc2=[]\n",
    "val_acc2=[]\n",
    "modelOutputName = 'LSTM-rnn.pt'\n",
    "\n",
    "N_EPOCHS = 30\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(modelL, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(modelL, valid_iterator, criterion)\n",
    "     \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(modelL.state_dict(), modelOutputName)\n",
    "    loss2.append(train_loss)\n",
    "    acc2.append(train_acc)\n",
    "    val_acc2.append(valid_acc)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I used MacBook to run the code, it was so slowly. I don't have enough time to run 50 epochs, so I used epoch = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Section 13: Plots\n",
    "plt.xlabel(\"runs\")\n",
    "plt.ylabel(\"normalised measure of loss/accuracy\")\n",
    "x_len=list(range(len(acc1)))\n",
    "plt.axis([0, max(x_len), 0, 1])\n",
    "plt.title('result of Vanilla')\n",
    "loss=np.asarray(loss1)/max(loss1)\n",
    "plt.plot(x_len, loss1, 'r.',label=\"loss\")\n",
    "plt.plot(x_len, acc1, 'b.', label=\"accuracy\")\n",
    "plt.plot(x_len, val_acc1, 'g.', label=\"val_accuracy\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.2)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"runs\")\n",
    "plt.ylabel(\"normalised measure of loss/accuracy\")\n",
    "x_len=list(range(len(acc2)))\n",
    "plt.axis([0, max(x_len), 0, 1])\n",
    "plt.title('result of LSTM')\n",
    "loss=np.asarray(loss2)/max(loss2)\n",
    "plt.plot(x_len, loss2, 'r.',label=\"loss\")\n",
    "plt.plot(x_len, acc2, 'b.', label=\"accuracy\")\n",
    "plt.plot(x_len, val_acc2, 'g.', label=\"val_accuracy\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.2)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Section 14: Test Code\n",
    "\n",
    "# 1. Load a saved model\n",
    "# 2. evaluate against the validation set (you will need to create )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'vanillaRNN_model.sav'\n",
    "pickle.dump(model, open(model_name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelL_name = 'LSTM_model.sav'\n",
    "pickle.dump(modelL, open(modelL_name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test. Acc: 82.70%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load the model from disk\n",
    "model_name = 'vanillaRNN_model.sav'\n",
    "#model_name = 'LSTM_model.sav' # We can switch model \n",
    "\n",
    "loaded_model = pickle.load(open(model_name, 'rb'))\n",
    "\n",
    "# reading test data\n",
    "#file_name = 'large-clean-test.json'\n",
    "test_data = data.TabularDataset(\n",
    "            path = dataFolder+'/'+file_name, \n",
    "            #test = file_name, #e.g. file_name = 'large-clean-test.json'\n",
    "            format = 'json', # json file\n",
    "            fields = fields)\n",
    "# processing test data \n",
    "test_iterator = data.BucketIterator(\n",
    "    test_data, \n",
    "    sort = False, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    sort_key = lambda x: len(x.t),\n",
    "    device = device)\n",
    "# evaluate against test data\n",
    "test_loss, test_acc = evaluate(loaded_model,test_iterator,criterion)\n",
    "print(f'Test. Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Section 15: Application\n",
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    print(model(tensor, length_tensor))\n",
    "    \n",
    "    prediction = torch.argmax(torch.exp(model(tensor, length_tensor)), dim=1)\n",
    "    return LABEL.vocab.itos[prediction.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.4553,  3.5597, -0.1363]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bad'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"This film is terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  7.5712, -11.5704,   3.9762]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(modelL, \"This film is great\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
